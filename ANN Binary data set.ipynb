{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2b6cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da574738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('E:/data sets dowload/breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20d1be0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a45a3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['id','Unnamed: 32'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a1037ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38           122.8     1001.0   \n",
       "1         M        20.57         17.77           132.9     1326.0   \n",
       "2         M        19.69         21.25           130.0     1203.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33            184.6   \n",
       "1         0.1812  ...         24.99          23.41            158.8   \n",
       "2         0.2069  ...         23.57          25.53            152.5   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "936b0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coverting into binary of dependent\n",
    "\n",
    "df['diagnosis']=df['diagnosis'].map({'M':0,'B':1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "556ffa3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          0        17.99         10.38          122.80     1001.0   \n",
       "1          0        20.57         17.77          132.90     1326.0   \n",
       "2          0        19.69         21.25          130.00     1203.0   \n",
       "3          0        11.42         20.38           77.58      386.1   \n",
       "4          0        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "385b0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "817cf7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37ee9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b273af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a1fc23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 381)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e86ec",
   "metadata": {},
   "source": [
    "# import packages and modules to develop ann model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1ce5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d0b678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation\n",
    "from tensorflow.keras.activations import sigmoid,relu,tanh,softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47b61132",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#dealing with frist hidden layer and agiving number of neurons  for x variabbe\n",
    "model.add(Dense(units=256,kernel_initializer='he_uniform',activation='relu',input_dim=X.shape[1]))\n",
    "#second hiddeen layer\n",
    "model.add(Dense(units=128,kernel_initializer='he_uniform',activation='relu'))\n",
    "#third hiddenlayer\n",
    "model.add(Dense(units=64,kernel_initializer='he_uniform',activation='relu'))\n",
    "#fourth hiddenlayer\n",
    "model.add(Dense(units=32,kernel_initializer='he_uniform',activation='relu'))\n",
    "#ffifth hiddenlayer\n",
    "model.add(Dense(units=16,kernel_initializer='he_uniform',activation='relu'))\n",
    "#Sixth hidden layer\n",
    "model.add(Dense(units=8,kernel_initializer='he_uniform',activation='relu'))\n",
    "# seventh\n",
    "model.add(Dense(units=4,kernel_initializer='he_uniform',activation='relu'))\n",
    "#eight\n",
    "model.add(Dense(units=2,kernel_initializer='he_uniform',activation='relu'))\n",
    "#output layer\n",
    "model.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))#why because only two labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8fb9a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61efd3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_37 (Dense)            (None, 256)               7936      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,881\n",
      "Trainable params: 51,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82ea5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter concept and also written notes \n",
    "model1=Sequential()\n",
    "#dealing with frist hidden layer and agiving number of neurons  for x variabbe\n",
    "model1.add(Dense(units=4,kernel_initializer='he_uniform',activation='relu',input_dim=2))\n",
    "#second hiddeen layer\n",
    "model1.add(Dense(units=3,kernel_initializer='he_uniform',activation='relu'))\n",
    "#output layer\n",
    "model1.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cc61453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 4)                 12        \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3ae0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for back trapping\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e8f960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "39/39 [==============================] - 5s 12ms/step - loss: 0.7228 - accuracy: 0.6247\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.6194\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6869 - accuracy: 0.6194\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6848 - accuracy: 0.6194\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.6826 - accuracy: 0.6194\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6811 - accuracy: 0.6194\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.6798 - accuracy: 0.6194\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.6783 - accuracy: 0.6194\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.6194\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.6756 - accuracy: 0.6194\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6746 - accuracy: 0.6194\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6736 - accuracy: 0.6194\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6726 - accuracy: 0.6194\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.6717 - accuracy: 0.6194\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6712 - accuracy: 0.6194\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6706 - accuracy: 0.6194\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6699 - accuracy: 0.6194\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6695 - accuracy: 0.6194\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.6692 - accuracy: 0.6194\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6686 - accuracy: 0.6194\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6682 - accuracy: 0.6194\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6679 - accuracy: 0.6194\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.6677 - accuracy: 0.6194\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.6673 - accuracy: 0.6194\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.6671 - accuracy: 0.6194\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6669 - accuracy: 0.6194\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.6668 - accuracy: 0.6194\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 1s 19ms/step - loss: 0.6665 - accuracy: 0.6194\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.6663 - accuracy: 0.6194\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6662 - accuracy: 0.6194\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.6659 - accuracy: 0.6194\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6659 - accuracy: 0.6194\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6656 - accuracy: 0.6194\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6655 - accuracy: 0.6194\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6654 - accuracy: 0.6194\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.6654 - accuracy: 0.6194\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6652 - accuracy: 0.6194\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6651 - accuracy: 0.6194\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 0.6194\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6651 - accuracy: 0.6194\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.6194\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6649 - accuracy: 0.6194\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6648 - accuracy: 0.6194\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6647 - accuracy: 0.6194\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6647 - accuracy: 0.6194\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6647 - accuracy: 0.6194\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.6647 - accuracy: 0.6194\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6646 - accuracy: 0.6194\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6646 - accuracy: 0.6194\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6646 - accuracy: 0.6194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218a4fe70a0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "feb2c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6203 - val_accuracy: 0.7179\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6206 - val_accuracy: 0.7179\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 0.6697 - accuracy: 0.6082 - val_loss: 0.6202 - val_accuracy: 0.7179\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6207 - val_accuracy: 0.7179\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6211 - val_accuracy: 0.7179\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6214 - val_accuracy: 0.7179\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6211 - val_accuracy: 0.7179\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6209 - val_accuracy: 0.7179\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6210 - val_accuracy: 0.7179\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6215 - val_accuracy: 0.7179\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6697 - accuracy: 0.6082 - val_loss: 0.6212 - val_accuracy: 0.7179\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6215 - val_accuracy: 0.7179\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6213 - val_accuracy: 0.7179\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6214 - val_accuracy: 0.7179\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6213 - val_accuracy: 0.7179\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6211 - val_accuracy: 0.7179\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6209 - val_accuracy: 0.7179\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6207 - val_accuracy: 0.7179\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6206 - val_accuracy: 0.7179\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6210 - val_accuracy: 0.7179\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6210 - val_accuracy: 0.7179\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6207 - val_accuracy: 0.7179\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6695 - accuracy: 0.6082 - val_loss: 0.6212 - val_accuracy: 0.7179\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6213 - val_accuracy: 0.7179\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6211 - val_accuracy: 0.7179\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6209 - val_accuracy: 0.7179\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 1s 16ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6209 - val_accuracy: 0.7179\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6208 - val_accuracy: 0.7179\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6206 - val_accuracy: 0.7179\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6208 - val_accuracy: 0.7179\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6211 - val_accuracy: 0.7179\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6214 - val_accuracy: 0.7179\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6214 - val_accuracy: 0.7179\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6213 - val_accuracy: 0.7179\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6215 - val_accuracy: 0.7179\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 1s 14ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6215 - val_accuracy: 0.7179\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6216 - val_accuracy: 0.7179\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6217 - val_accuracy: 0.7179\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6219 - val_accuracy: 0.7179\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6218 - val_accuracy: 0.7179\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6214 - val_accuracy: 0.7179\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6217 - val_accuracy: 0.7179\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6218 - val_accuracy: 0.7179\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6217 - val_accuracy: 0.7179\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6216 - val_accuracy: 0.7179\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6697 - accuracy: 0.6082 - val_loss: 0.6213 - val_accuracy: 0.7179\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6215 - val_accuracy: 0.7179\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6211 - val_accuracy: 0.7179\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6697 - accuracy: 0.6082 - val_loss: 0.6206 - val_accuracy: 0.7179\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6696 - accuracy: 0.6082 - val_loss: 0.6211 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218a9325a90>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by kepping validation\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=10,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177093db",
   "metadata": {},
   "source": [
    "# Checking with small architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c738bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "#dealing with frist hidden layer and agiving number of neurons  for x variabbe\n",
    "model2.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu',input_dim=X.shape[1]))\n",
    "#second hiddeen layer\n",
    "model2.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu'))\n",
    "#output layer\n",
    "model2.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a5bc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e9b6a35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 3s 32ms/step - loss: 308.2169 - accuracy: 0.6082 - val_loss: 176.0002 - val_accuracy: 0.7179\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 218.8964 - accuracy: 0.6082 - val_loss: 126.4042 - val_accuracy: 0.7179\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 154.9417 - accuracy: 0.6082 - val_loss: 81.7835 - val_accuracy: 0.7179\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 78.0946 - accuracy: 0.6082 - val_loss: 22.9441 - val_accuracy: 0.7179\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 10.2460 - accuracy: 0.4678 - val_loss: 3.0086 - val_accuracy: 0.2564\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.3987 - accuracy: 0.4591 - val_loss: 1.4612 - val_accuracy: 0.5128\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 1.1366 - accuracy: 0.4766 - val_loss: 1.4083 - val_accuracy: 0.4615\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.0332 - accuracy: 0.5088 - val_loss: 1.2898 - val_accuracy: 0.5385\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.9193 - accuracy: 0.5585 - val_loss: 1.3091 - val_accuracy: 0.4872\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 3s 86ms/step - loss: 0.8182 - accuracy: 0.5731 - val_loss: 1.2265 - val_accuracy: 0.5128\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.7778 - accuracy: 0.5877 - val_loss: 1.0219 - val_accuracy: 0.6154\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7042 - accuracy: 0.6228 - val_loss: 0.9478 - val_accuracy: 0.6410\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.6537 - accuracy: 0.6579 - val_loss: 0.9003 - val_accuracy: 0.6923\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.6104 - accuracy: 0.6959 - val_loss: 0.8370 - val_accuracy: 0.7179\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5693 - accuracy: 0.7076 - val_loss: 0.7786 - val_accuracy: 0.7436\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5392 - accuracy: 0.7251 - val_loss: 0.6971 - val_accuracy: 0.7436\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.5129 - accuracy: 0.7690 - val_loss: 0.7061 - val_accuracy: 0.7436\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7749 - val_loss: 0.6440 - val_accuracy: 0.7692\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.8158 - val_loss: 0.6367 - val_accuracy: 0.7436\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.8246 - val_loss: 0.6458 - val_accuracy: 0.7436\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.8275 - val_loss: 0.6477 - val_accuracy: 0.7949\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8392 - val_loss: 0.6408 - val_accuracy: 0.7949\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.8070 - val_loss: 0.5839 - val_accuracy: 0.7436\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8450 - val_loss: 0.5725 - val_accuracy: 0.7179\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3883 - accuracy: 0.8333 - val_loss: 0.7232 - val_accuracy: 0.7692\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.8275 - val_loss: 0.5650 - val_accuracy: 0.7692\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3649 - accuracy: 0.8655 - val_loss: 0.5574 - val_accuracy: 0.7436\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3662 - accuracy: 0.8509 - val_loss: 0.5608 - val_accuracy: 0.7692\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8713 - val_loss: 0.5290 - val_accuracy: 0.7436\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3715 - accuracy: 0.8655 - val_loss: 0.5901 - val_accuracy: 0.8205\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8567 - val_loss: 0.6512 - val_accuracy: 0.7949\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8421 - val_loss: 0.5289 - val_accuracy: 0.7436\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8713 - val_loss: 0.5371 - val_accuracy: 0.7949\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8421 - val_loss: 0.5374 - val_accuracy: 0.7949\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3224 - accuracy: 0.8596 - val_loss: 0.5271 - val_accuracy: 0.8205\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3095 - accuracy: 0.8801 - val_loss: 0.5223 - val_accuracy: 0.8205\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3095 - accuracy: 0.8713 - val_loss: 0.5187 - val_accuracy: 0.7692\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.8772 - val_loss: 0.5189 - val_accuracy: 0.7949\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8713 - val_loss: 0.5189 - val_accuracy: 0.7949\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8830 - val_loss: 0.5215 - val_accuracy: 0.8205\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3185 - accuracy: 0.8772 - val_loss: 0.5309 - val_accuracy: 0.8205\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8860 - val_loss: 0.5297 - val_accuracy: 0.8205\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2936 - accuracy: 0.8830 - val_loss: 0.5172 - val_accuracy: 0.7949\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.3042 - accuracy: 0.8860 - val_loss: 0.5329 - val_accuracy: 0.7692\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2857 - accuracy: 0.8830 - val_loss: 0.5279 - val_accuracy: 0.7692\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 1s 14ms/step - loss: 0.2833 - accuracy: 0.8860 - val_loss: 0.5187 - val_accuracy: 0.7949\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2956 - accuracy: 0.8947 - val_loss: 0.5749 - val_accuracy: 0.7949\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2857 - accuracy: 0.8772 - val_loss: 0.6453 - val_accuracy: 0.7949\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3295 - accuracy: 0.8743 - val_loss: 0.5203 - val_accuracy: 0.7949\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2912 - accuracy: 0.8772 - val_loss: 0.5334 - val_accuracy: 0.7949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218ad3c4160>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train,epochs=50,batch_size=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a69d93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from above it is clear that it is working for small architeture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "40fbe8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ad5556b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6081871390342712,\n",
       " 0.6081871390342712,\n",
       " 0.6081871390342712,\n",
       " 0.6081871390342712,\n",
       " 0.46783626079559326,\n",
       " 0.4590643346309662,\n",
       " 0.47660818696022034,\n",
       " 0.5087719559669495,\n",
       " 0.5584795475006104,\n",
       " 0.5730994343757629,\n",
       " 0.5877193212509155,\n",
       " 0.6228070259094238,\n",
       " 0.6578947305679321,\n",
       " 0.6959064602851868,\n",
       " 0.707602322101593,\n",
       " 0.7251461744308472,\n",
       " 0.7690058350563049,\n",
       " 0.7748538255691528,\n",
       " 0.8157894611358643,\n",
       " 0.8245614171028137,\n",
       " 0.8274853825569153,\n",
       " 0.8391813039779663,\n",
       " 0.8070175647735596,\n",
       " 0.8450292348861694,\n",
       " 0.8333333134651184,\n",
       " 0.8274853825569153,\n",
       " 0.8654970526695251,\n",
       " 0.8508771657943726,\n",
       " 0.871345043182373,\n",
       " 0.8654970526695251,\n",
       " 0.8567251563072205,\n",
       " 0.8421052694320679,\n",
       " 0.871345043182373,\n",
       " 0.8421052694320679,\n",
       " 0.859649121761322,\n",
       " 0.8801169395446777,\n",
       " 0.871345043182373,\n",
       " 0.8771929740905762,\n",
       " 0.871345043182373,\n",
       " 0.8830409646034241,\n",
       " 0.8771929740905762,\n",
       " 0.8859649300575256,\n",
       " 0.8830409646034241,\n",
       " 0.8859649300575256,\n",
       " 0.8830409646034241,\n",
       " 0.8859649300575256,\n",
       " 0.8947368264198303,\n",
       " 0.8771929740905762,\n",
       " 0.8742690086364746,\n",
       " 0.8771929740905762]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "07787851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.title('trainig plot')\n",
    "plt.plot(np.arange(50),model2.history.history['loss'],label='loss')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('total epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('trainig plot')\n",
    "plt.plot(np.arange(50),model2.history.history['accuracy'])\n",
    "plt.xlabel('total epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aafbf18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from above it is clear that loss is reduced and accuracy is increased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2da84",
   "metadata": {},
   "source": [
    "# test data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3bdc6c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12.47</td>\n",
       "      <td>18.60</td>\n",
       "      <td>81.09</td>\n",
       "      <td>481.9</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.08005</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.06373</td>\n",
       "      <td>...</td>\n",
       "      <td>14.97</td>\n",
       "      <td>24.64</td>\n",
       "      <td>96.05</td>\n",
       "      <td>677.9</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.08750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>18.94</td>\n",
       "      <td>21.31</td>\n",
       "      <td>123.60</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0.09009</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.07951</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05461</td>\n",
       "      <td>...</td>\n",
       "      <td>24.86</td>\n",
       "      <td>26.58</td>\n",
       "      <td>165.90</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>0.06589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>12.40</td>\n",
       "      <td>17.68</td>\n",
       "      <td>81.47</td>\n",
       "      <td>467.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.07741</td>\n",
       "      <td>0.02799</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.07102</td>\n",
       "      <td>...</td>\n",
       "      <td>12.88</td>\n",
       "      <td>22.91</td>\n",
       "      <td>89.61</td>\n",
       "      <td>515.8</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.07370</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.09359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>11.54</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.06737</td>\n",
       "      <td>0.02594</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>...</td>\n",
       "      <td>12.26</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "204        12.47         18.60           81.09      481.9          0.09965   \n",
       "70         18.94         21.31          123.60     1130.0          0.09009   \n",
       "131        15.46         19.48          101.70      748.9          0.10920   \n",
       "431        12.40         17.68           81.47      467.8          0.10540   \n",
       "540        11.54         14.44           74.65      402.9          0.09984   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "204            0.1058         0.08005              0.03821         0.1925   \n",
       "70             0.1029         0.10800              0.07951         0.1582   \n",
       "131            0.1223         0.14660              0.08087         0.1931   \n",
       "431            0.1316         0.07741              0.02799         0.1811   \n",
       "540            0.1120         0.06737              0.02594         0.1818   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "204                 0.06373  ...         14.97          24.64   \n",
       "70                  0.05461  ...         24.86          26.58   \n",
       "131                 0.05796  ...         19.26          26.00   \n",
       "431                 0.07102  ...         12.88          22.91   \n",
       "540                 0.06782  ...         12.26          19.68   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "204            96.05       677.9            0.1426             0.2378   \n",
       "70            165.90      1866.0            0.1193             0.2336   \n",
       "131           124.90      1156.0            0.1546             0.2394   \n",
       "431            89.61       515.8            0.1450             0.2629   \n",
       "540            78.78       457.8            0.1345             0.2118   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "204           0.2671               0.10150          0.3014   \n",
       "70            0.2687               0.17890          0.2551   \n",
       "131           0.3791               0.15140          0.2837   \n",
       "431           0.2403               0.07370          0.2556   \n",
       "540           0.1797               0.06918          0.2329   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "204                  0.08750  \n",
       "70                   0.06589  \n",
       "131                  0.08019  \n",
       "431                  0.09359  \n",
       "540                  0.08134  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c858e5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 30)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cc9e041f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis\n",
       "204          1\n",
       "70           0\n",
       "131          0\n",
       "431          1\n",
       "540          1"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "06f57c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.247e+01 1.860e+01 8.109e+01 4.819e+02 9.965e-02 1.058e-01 8.005e-02\n",
      "  3.821e-02 1.925e-01 6.373e-02 3.961e-01 1.044e+00 2.497e+00 3.029e+01\n",
      "  6.953e-03 1.911e-02 2.701e-02 1.037e-02 1.782e-02 3.586e-03 1.497e+01\n",
      "  2.464e+01 9.605e+01 6.779e+02 1.426e-01 2.378e-01 2.671e-01 1.015e-01\n",
      "  3.014e-01 8.750e-02]]\n"
     ]
    }
   ],
   "source": [
    "bb=X_test.iloc[0,:]\n",
    "bb1=np.array([bb])\n",
    "print(bb1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5e6b4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "checking=X_test.head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7c68f29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.247e+01, 1.860e+01, 8.109e+01, 4.819e+02, 9.965e-02, 1.058e-01,\n",
       "        8.005e-02, 3.821e-02, 1.925e-01, 6.373e-02, 3.961e-01, 1.044e+00,\n",
       "        2.497e+00, 3.029e+01, 6.953e-03, 1.911e-02, 2.701e-02, 1.037e-02,\n",
       "        1.782e-02, 3.586e-03, 1.497e+01, 2.464e+01, 9.605e+01, 6.779e+02,\n",
       "        1.426e-01, 2.378e-01, 2.671e-01, 1.015e-01, 3.014e-01, 8.750e-02]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeffbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheking and bb are containg same values means have taken values 0f 207 in x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0b73527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7037333]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in above as probabability is more than 0.7 it belongs to 1,we can also check in y_test it is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f341dc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis\n",
       "204          1\n",
       "70           0\n",
       "131          0\n",
       "431          1\n",
       "540          1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "38f667bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "xtest_data=model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "46b8ca6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.03731418e-01],\n",
       "       [1.04596882e-06],\n",
       "       [7.00714206e-03],\n",
       "       [9.93277967e-01],\n",
       "       [9.76043940e-01],\n",
       "       [2.77415675e-05],\n",
       "       [2.98262499e-08],\n",
       "       [9.07736085e-03],\n",
       "       [9.91848350e-01],\n",
       "       [9.74919558e-01],\n",
       "       [9.10969138e-01],\n",
       "       [9.04576911e-04],\n",
       "       [9.27978814e-01],\n",
       "       [2.42117327e-02],\n",
       "       [9.91895258e-01],\n",
       "       [1.42710237e-02],\n",
       "       [9.27343428e-01],\n",
       "       [9.87520337e-01],\n",
       "       [9.89677250e-01],\n",
       "       [3.13489836e-05],\n",
       "       [8.94321978e-01],\n",
       "       [9.40910518e-01],\n",
       "       [9.87334079e-06],\n",
       "       [9.84167516e-01],\n",
       "       [9.67077971e-01],\n",
       "       [9.02907908e-01],\n",
       "       [9.88363087e-01],\n",
       "       [9.78348255e-01],\n",
       "       [9.65452313e-01],\n",
       "       [9.95442133e-06],\n",
       "       [9.75729942e-01],\n",
       "       [9.87281740e-01],\n",
       "       [4.65160459e-01],\n",
       "       [9.41116750e-01],\n",
       "       [9.87423956e-01],\n",
       "       [9.35241401e-01],\n",
       "       [1.60438810e-02],\n",
       "       [6.63541853e-01],\n",
       "       [6.98773540e-04],\n",
       "       [3.59586149e-01],\n",
       "       [9.59750056e-01],\n",
       "       [1.47821731e-03],\n",
       "       [9.88874257e-01],\n",
       "       [9.63316441e-01],\n",
       "       [3.65156621e-01],\n",
       "       [9.58572090e-01],\n",
       "       [9.82318640e-01],\n",
       "       [8.57295454e-01],\n",
       "       [9.63660538e-01],\n",
       "       [9.59038854e-01],\n",
       "       [2.59209098e-03],\n",
       "       [1.30969829e-06],\n",
       "       [9.80761170e-01],\n",
       "       [5.43301344e-01],\n",
       "       [9.72367883e-01],\n",
       "       [9.40442562e-01],\n",
       "       [9.54266489e-01],\n",
       "       [1.70708205e-07],\n",
       "       [9.48721051e-01],\n",
       "       [9.91814733e-01],\n",
       "       [9.42345440e-01],\n",
       "       [1.09486427e-05],\n",
       "       [3.43823370e-09],\n",
       "       [8.62854779e-01],\n",
       "       [9.77189958e-01],\n",
       "       [9.07846808e-01],\n",
       "       [5.24559815e-04],\n",
       "       [7.53099857e-06],\n",
       "       [9.79302049e-01],\n",
       "       [9.73287463e-01],\n",
       "       [6.85133338e-02],\n",
       "       [1.19999133e-03],\n",
       "       [9.79400992e-01],\n",
       "       [3.98187727e-01],\n",
       "       [9.31254447e-01],\n",
       "       [9.87537086e-01],\n",
       "       [8.50322425e-01],\n",
       "       [4.10118222e-01],\n",
       "       [9.79526639e-01],\n",
       "       [9.88426328e-01],\n",
       "       [1.31924320e-02],\n",
       "       [9.82250035e-01],\n",
       "       [3.20805311e-01],\n",
       "       [1.35831320e-08],\n",
       "       [1.52373267e-02],\n",
       "       [1.56460572e-02],\n",
       "       [5.47381639e-01],\n",
       "       [5.15061811e-06],\n",
       "       [9.95934188e-01],\n",
       "       [9.79272544e-01],\n",
       "       [9.67774689e-01],\n",
       "       [9.61612821e-01],\n",
       "       [4.84155953e-01],\n",
       "       [9.24301803e-01],\n",
       "       [9.75044787e-01],\n",
       "       [9.64660704e-01],\n",
       "       [7.24293386e-06],\n",
       "       [1.43059937e-03],\n",
       "       [9.88361299e-01],\n",
       "       [2.13093706e-03],\n",
       "       [4.72756382e-03],\n",
       "       [9.93044496e-01],\n",
       "       [3.84106116e-08],\n",
       "       [9.95297264e-03],\n",
       "       [7.05030978e-01],\n",
       "       [7.95798659e-01],\n",
       "       [9.45653379e-01],\n",
       "       [1.64582692e-12],\n",
       "       [9.50025678e-01],\n",
       "       [8.32813621e-01],\n",
       "       [1.61931195e-04],\n",
       "       [9.70167637e-01],\n",
       "       [4.22000974e-01],\n",
       "       [1.61535625e-18],\n",
       "       [9.60597157e-01],\n",
       "       [3.27453790e-06],\n",
       "       [9.68000948e-01],\n",
       "       [9.46016133e-01],\n",
       "       [8.35588276e-01],\n",
       "       [3.06012183e-01],\n",
       "       [3.53659038e-03],\n",
       "       [9.89605904e-01],\n",
       "       [9.65206921e-01],\n",
       "       [2.13252753e-03],\n",
       "       [9.42608893e-01],\n",
       "       [1.04966475e-05],\n",
       "       [4.53071408e-02],\n",
       "       [9.25046027e-01],\n",
       "       [9.76982951e-01],\n",
       "       [4.62566386e-05],\n",
       "       [1.14829875e-10],\n",
       "       [7.66075552e-01],\n",
       "       [8.29432011e-01],\n",
       "       [9.89486992e-01],\n",
       "       [8.60468447e-01],\n",
       "       [1.57349572e-01],\n",
       "       [9.37400162e-01],\n",
       "       [9.38409209e-01],\n",
       "       [3.57883692e-01],\n",
       "       [5.16862869e-01],\n",
       "       [9.82294142e-01],\n",
       "       [1.61955316e-09],\n",
       "       [9.93963420e-01],\n",
       "       [9.89865482e-01],\n",
       "       [4.05946076e-01],\n",
       "       [9.66243267e-01],\n",
       "       [4.29951865e-03],\n",
       "       [9.02497140e-06],\n",
       "       [6.88495219e-01],\n",
       "       [8.13774765e-01],\n",
       "       [1.50588512e-01],\n",
       "       [8.81161392e-01],\n",
       "       [9.92814898e-01],\n",
       "       [8.38350594e-01],\n",
       "       [9.89336550e-01],\n",
       "       [1.00398155e-10],\n",
       "       [8.98409635e-03],\n",
       "       [9.29143548e-01],\n",
       "       [8.52262795e-01],\n",
       "       [9.94514942e-01],\n",
       "       [9.88298297e-01],\n",
       "       [9.89437103e-01],\n",
       "       [8.94083023e-01],\n",
       "       [9.39875603e-01],\n",
       "       [3.21102776e-02],\n",
       "       [9.73759770e-01],\n",
       "       [9.73246932e-01],\n",
       "       [6.08129442e-01],\n",
       "       [9.17483866e-01],\n",
       "       [2.33321801e-01],\n",
       "       [9.91498232e-01],\n",
       "       [8.85849535e-01],\n",
       "       [9.74894702e-01],\n",
       "       [2.82676101e-01],\n",
       "       [9.76560235e-01],\n",
       "       [5.19381106e-01],\n",
       "       [2.62545925e-02],\n",
       "       [9.64296341e-01],\n",
       "       [8.70222390e-01],\n",
       "       [9.00817394e-01],\n",
       "       [8.41299117e-01],\n",
       "       [9.43218768e-01],\n",
       "       [9.94744062e-01],\n",
       "       [2.53922917e-04],\n",
       "       [7.32629906e-06],\n",
       "       [2.56498083e-02],\n",
       "       [8.74433160e-01],\n",
       "       [9.09034133e-01]], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "69379b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 1)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "559e1a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 30)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "94e29870",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[]\n",
    "for i in xtest_data:#outer list\n",
    "    for j in i:#inner list\n",
    "        if j>0.5:\n",
    "            c.append(1)\n",
    "        else:\n",
    "            c.append(0)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d926c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2f584cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d96ace41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925531914893617"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3ebbee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61,   6],\n",
       "       [  8, 113]], dtype=int64)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bb939323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90        67\n",
      "           1       0.95      0.93      0.94       121\n",
      "\n",
      "    accuracy                           0.93       188\n",
      "   macro avg       0.92      0.92      0.92       188\n",
      "weighted avg       0.93      0.93      0.93       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7520114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
